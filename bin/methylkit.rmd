---
params:
  study: "Study Name"
  metadata_path: "path/to/metadata.csv"
  bismark_path: "path/to/bismark"
  chromhmm_path: "path/to/chromhmm_segments.bed"
  ccre_path: "path/to/cCREs.bed"
  blacklist_path: "path/to/blacklist.bed"
  out_path: "path/to/methylkit"
  assembly: "genome_assembly"
title: |
  | Differential methylation analysis report
  | `r params$study`
date: "`r Sys.Date()`"
author: "`r Sys.info()[['user']]`"
version: "1.0"
output:
  rmdformats::readthedown:
    toc_depth: 6
    self_contained: yes
    
css: methylkit.css
---
<!--
# Differential Methylation Analysis Report
This R Markdown document performs differential methylation analysis for a specified study. 
It includes QC analysis, statistical analysis, and visualization of results.


Usage from R console:
rmarkdown::render(
  "bin/methylkit.rmd", 
  params = list(
    study = "JIRA_BDS-XXXX_12ABIC_EPI321_vs_CONTROL", 
    metadata_path = "/home/tylerborrman/epic-methylseq_data/test_12ABIC/samplesheet_test_12ABIC.csv",
    bismark_path = "/home/tylerborrman/epic-methylseq_data/test_12ABIC",
    chromhmm_path = "/home/tylerborrman/epic-methylseq_data/ChromHMM/hg38_genome_100_segments.bed",
    ccre_path = "/home/tylerborrman/epic-methylseq_data/cCRE/GRCh38-cCREs.bed",
    blacklist_path = "/home/tylerborrman/epic-methylseq_data/blacklist/hg38-blacklist.v2.bed",
    out_path = "/home/tylerborrman/epic-methylseq_data/test_12ABIC/methylkit",
    assembly = "hg38"
  )
)

Usage from command line:
Rscript -e "rmarkdown::render(
  'bin/methylkit.rmd',
  params = list(
    study = 'JIRA_BDS-XXXX_12ABIC_EPI321_vs_CONTROL',
    metadata_path = '/home/tylerborrman/epic-methylseq_data/test_12ABIC/samplesheet_test_12ABIC.csv',
    bismark_path = '/home/tylerborrman/epic-methylseq_data/test_12ABIC',
    chromhmm_path = "/home/tylerborrman/epic-methylseq_data/ChromHMM/hg38_genome_100_segments.bed",
    ccre_path = "/home/tylerborrman/epic-methylseq_data/cCRE/GRCh38-cCREs.bed",
    blacklist_path = "/home/tylerborrman/epic-methylseq_data/blacklist/hg38-blacklist.v2.bed",
    out_path = '/home/tylerborrman/epic-methylseq_data/test_12ABIC/methylkit',
    assembly = 'hg38'
  )
)"

params:
  study: Study Name with JIRA ID prefix
  metadata_path: path to samplesheet used in nfcore/methylseq pipeline with additional condition column
  bismark_path: path to directory containing bismark coverage files (.deduplicated.bismark.cov)
  chromhmm_path = path to ChromHMM annotation file
  ccre_path = path to ENCDOE cCRE annotation file
  blacklist_path = path to ENCODE blacklist annotation file
  out_path: path to directory to save methylkit output files
  assembly: genome assembly used in the analysis (e.g. hg38, mm10)
-->

```{r setup, include=FALSE} 
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, cache=FALSE)
# load packages
library(DT)
library(methylKit)
library(plotly)
library(ggplot2)
library(dplyr)
library(tidyr)
library(readr)
library(GenomicRanges)
library(rtracklayer)
```

# Dataset overview

```{r dataset overview}
# Load metadata
metadata <- read_csv(params$metadata_path)
metadata <- metadata[c("sample", "condition")]
datatable(metadata)
metadata <- as.data.frame(metadata)
rownames(metadata) <- metadata$sample
condition <- metadata$condition
names(condition) <- metadata$sample

```

# Descriptive statistics

```{r descriptive statistics}

# Function to find files with a given prefix
find_files_with_prefix <- function(prefix, files) {
  matching_files <- grep(prefix, files, value = TRUE)
  if (length(matching_files) == 1) {
    return(matching_files)
  } else {
    stop(paste0("ERROR: No file or multiple files found for sample with prefix ", prefix))
  }
}
unordered_files <- list.files(
  params$bismark_path,
  pattern = ".cov",
  full.names = TRUE
)
# Ensure files are ordered according to metadata sample sheet
cov_files <- as.list(sapply(metadata$sample, find_files_with_prefix, files = unordered_files))

# Currently only supporting EPI321 vs Control comparison
treatment <- ifelse(metadata$condition == "EPI321", 1, 0)
treated <- metadata$sample[metadata$condition == "EPI321"]
control <- metadata$sample[metadata$condition == "CONTROL"]

# read methylation call files and store them as flat file database
# Note gzipped files are supported
# Note that the doc for methylKit says bismark coverage files have 5 cols, 
# but the bismark coverage files have 6 cols and the code for the methylKit methRead function expects 6 cols:
# chr, start, end, % meth, count methylated, count unmethylated

myobj=methRead(cov_files,
                sample.id=as.list(metadata$sample),
                pipeline="bismarkCoverage",
                assembly=params$assembly,
                treatment=treatment,
                context="CpG",
                dbtype = "tabix",
                dbdir = "methylDB",
                header = FALSE
)

# Descriptive statistics on samples
getMethylationStats(myobj[[1]],plot=TRUE,both.strands=FALSE) # check methylation stats on first sample
getCoverageStats(myobj[[1]],plot=TRUE,both.strands=FALSE) # check coverage stats on first  sample 
```

# Comparative Analysis
## CpG analysis
```{r comparative analysis}
# Comparative analysis
#  Merging all samples into one file. This is needed as precursor for dmc analyses  
meth=methylKit::unite(myobj, destrand=FALSE)
clusterSamples(meth, dist="correlation", method="ward.D2", plot=TRUE)
PCASamples(meth, screeplot=TRUE)
PCASamples(meth, adj.lim=c(0.5,0.5))
```

# PCA
PCA analysis on % methylation matrix *X* where *X(i,j)*
represents the % methylation of CpG *j* in sample *i*.

## Biplot
```{r pca, fig.height=9, fig.width=11}
# Adjust the range of a vector "x" by "i" proportion of the range of x
# 
# @param x a vector of value
# @param i the proprotion of the range of x to adjust the size.
.adjlim=function(x, i)
  {
  if(length(x)>1) {
    xr=range(x); 
    xlim=c(); 
    xlim[1]=xr[1] - abs(xr[1]) * i; 
    xlim[2]=xr[2] + abs(xr[2] * i); 
    return(xlim)} 
  else 
    print("length vector x should be more than 1")
  }

rowSds <- function(x, center=NULL, ...) {
  n <- !is.na(x);
  n <- rowSums(n);
  n[n <= 1] <- NA;

  if (is.null(center)) {
    center <- rowMeans(x, ...);
  }

  x <- x - center;
  x <- x*x;
  x <- rowSums(x, ...);
  x <- x/(n-1);

 sqrt(x);
}

#' convert methylKit tabix to data.frame
# assuming you get a list length 1
#' @noRd
tabix2df<-function(tabixRes){

    data.table::fread( paste0(paste(tabixRes[[1]],collapse="\n"),"\n" ),
                       stringsAsFactors=FALSE,data.table = FALSE)
    
}

#' get data from already opened tabixfile for a given chunkSize
#'
# @example
# tbxFile=methylRawListDB[[1]]@dbpath
#  getTabixByChunk( tbxFile,chunk.size=10)
#' @noRd
getTabixByChunk<-function(tbxFile,chunk.size=1e6,
                          return.type=c("data.table","data.frame","GRanges")){
  
  return.type <- match.arg(return.type)
  
  if( class(tbxFile) != "TabixFile" | !Rsamtools::isOpen(tbxFile, rw="read") ){
    stop("tbxFile has to be a class of TabixFile and should be open for reading ")
  }
  
  if(is.na(Rsamtools::yieldSize(tbxFile)) | is.numeric(chunk.size)  ){
    Rsamtools::yieldSize(tbxFile)<-chunk.size
  }
  
  res <- Rsamtools::scanTabix(tbxFile)
  if(length(res) == 1 & length(res[[1]]) == 0)
    stop("the tabix file seems to be empty. stopping here.")
  
  if(return.type=="data.table")
  {
    tabix2dt(res)
  }else if (return.type=="data.frame"){
    tabix2df(res)
  }else {
    tabix2gr(res)
  }
}

# applyTbxByChunk
#' Serially apply a function on chunks of tabix files
#' 
#' The function reads chunks of a tabix file and applies a function on them. 
#' The function (FUN argument) should apply on data.frames and 
#' return a data frame
#' as a result. The function is serially applied to chunks 
#' (means no parallelization). 
#' However, the function FUN itself can be a parallelized function
#' and related arguments could be passed on to the function via ... argument.
#' 
#' @param tbxFile tabix file to read. a TabixFile object
#' @param chunk.size number of rows to be taken as a chunk, default: 1e6
#' @param return.type indicates the return type for the function
#' @param FUN function to apply to chunks, it takes a data.frame and returns a 
#'            data.frame. First argument of the function should be a data frame
#' @param ... parameters to be passed to FUN. 
#' @param dir directory to create temporary files and the resulting tabix file
#' @param filename the filename for the resulting tabix file, this should not be 
#' a path, just a file name.
#' @param tabixHead optional header to prepend to the file
#'
#' @return either a path to a tabix or text file, or a data frame or data.table
#' @noRd
applyTbxByChunk<-function(tbxFile,chunk.size=1e6,dir,filename,
                          return.type=c("tabix","data.frame","data.table","text"),
                          FUN,...,tabixHead=NULL,textHeader=NULL){
  
  return.type <- match.arg(return.type)
  FUN <- match.fun(FUN)
  
  # open tabix file with given chunk size
  if( class(tbxFile) != "TabixFile" ){
    tbxFile <- Rsamtools::TabixFile(tbxFile, yieldSize = chunk.size)

  } else {
    if(Rsamtools::isOpen(tbxFile)){close(tbxFile)}# close if already open
    Rsamtools::yieldSize(tbxFile) <-  chunk.size 
  }
  
  
  # calculate number of chunks
  recs=Rsamtools::countTabix(tbxFile)[[1]]
  chunk.num=ceiling(recs/chunk.size)
  
  open(tbxFile)
  
  if(return.type =="tabix"){
    
    # create a custom function that contains the function
    # to be applied
    myFunc<-function(chunk.num,tbxFile,dir,filename,FUN,...){
      data=getTabixByChunk(tbxFile,chunk.size=NULL,return.type="data.frame")
      res=FUN(data,...)  
      
      # for tabix
      outfile= file.path(path.expand( dir),paste(chunk.num,filename,sep="_"))
      .write.table.noSci(res,outfile,quote=FALSE,col.names=FALSE,row.names=FALSE,
                  sep="\t")
    }

    # attach a random string to the file name 
    rndFile=paste(sample(c(0:9, letters, LETTERS),9, replace=TRUE),collapse="")
    filename2=paste(rndFile,filename,sep="_")
    
    # apply function to chunks
    res=lapply(1:chunk.num,myFunc,tbxFile,dir,filename2,FUN,...)
    
    # collect & cat temp files,then make tabix
    path <- catsub2tabix(dir,pattern=filename2,filename,sort = TRUE,tabixHead = tabixHead)

    return(gsub(".tbi","",path))
    
  } else if(return.type =="text"){
    
    # create a custom function that contains the function
    # to be applied
    myFunc2<-function(chunk.num,tbxFile,dir,filename,FUN,...){
      data=getTabixByChunk(tbxFile,chunk.size=NULL,return.type="data.frame")
      res=FUN(data,...)  
      
      # for text
      outfile= file.path(path.expand( dir),paste(chunk.num,filename,sep="_"))
      .write.table.noSci(res,outfile,quote=FALSE,col.names=FALSE,row.names=FALSE,
                  sep="\t")
    }
    
    # attach a random string to the file name 
    rndFile=paste(sample(c(0:9, letters, LETTERS),9, replace=TRUE),collapse="")
    filename2=paste(rndFile,filename,sep="_")
    
    # apply function to chunks
    res=lapply(1:chunk.num,myFunc2,tbxFile,dir,filename2,FUN,...)
    
    
    outfile= file.path(path.expand(dir),filename) # get file name 
    if(file.exists(outfile)){
      message("overwriting ",outfile)
      unlink(outfile)
    }
    con=file(outfile, open = "a", blocking = TRUE) # open connection  
    # write header if provided
    if(!is.null(textHeader)) 
      write(file = con,
            x = textHeader,
            ncolumns = length(textHeader),
            sep = "\t")
    # append result files
    for(file in gtools::mixedsort(
      list.files(path = dir, pattern = filename2,full.names=TRUE))){
      file.append(outfile,file) # append files
    }
    close(con)
    #remove temp files
    unlink(list.files(path = dir, pattern = filename2,full.names=TRUE))
    
    return(outfile)
  
  }else if(return.type=="data.frame"){
    
    # create a custom function that contains the function
    # to be applied
    myFunc3<-function(chunk.num,tbxFile,FUN,...){
      data=getTabixByChunk(tbxFile,chunk.size=NULL,return.type="data.frame")
      FUN(data,...)    
    }
    
    res=lapply(1:chunk.num,myFunc3,tbxFile,FUN,...)
    
    # collect and return
    data.frame(data.table::rbindlist(res))
  }else{
    
    myFunc4<-function(chunk.num,tbxFile,FUN,...){
      data=getTabixByChunk(tbxFile,chunk.size=NULL,return.type="data.table")
      FUN(data,...)    
    }
    
    res=lapply(1:chunk.num,myFunc4,tbxFile,FUN,...)
  
    
    # collect and return
    data.table::rbindlist(res)
  }
  
}

# Principal Components Analysis on methylBase object
# x matrix each column is a sample
# cor a logical value indicating whether the calculation should use the correlation matrix or the covariance matrix. (The correlation matrix can only be used if there are no constant variables.)
.myPcaPlot = function(x,comp1=1,comp2=2, screeplot=FALSE, adj.lim=c(0.001,0.1), treatment=treatment,sample.ids=sample.ids,context,scale=TRUE,center=TRUE,obj.return=FALSE){
  #x.pr = princomp(x, cor=cor)
  

  x.pr = prcomp((x),scale.=scale,center=center)

  if (screeplot){
    i=5;screeplot(x.pr, type="barplot", main=paste(context,"methylation PCA Screeplot"), col = rainbow(i)[i])
  }
  else{
    #loads = loadings(x.pr)
    loads = x.pr$rotation
    treatment=treatment
    sample.ids=sample.ids
    my.cols=rainbow(length(unique(treatment)), start=1, end=0.6)

    
    plot(loads[,comp1],loads[,comp2], main = paste(context,"methylation PCA Analysis"),
         col=my.cols[treatment+1],
         xlim=.adjlim(loads[,comp1],adj.lim[1]), 
         ylim=.adjlim(loads[,comp2], adj.lim[2]),
         xlab=paste("loadings for PC",comp1,sep=""), 
         ylab=paste("loadings for PC",comp2,sep=""))
    
    text(loads[,comp1], loads[,comp2],labels=sample.ids,adj=c(-0.4,0.3), 
         col=my.cols[treatment+1])
  }
  if(obj.return){  return((x.pr))}

}


# Principal Components Analysis on methylBase object on transposed data
# x matrix each column is a sample
.myPcaPlotT = function(x,comp1=1,comp2=2,screeplot=FALSE, adj.lim=c(0.001,0.1),
                     treatment=treatment,sample.ids=sample.ids,context,
                     scale=TRUE,center=TRUE,obj.return=FALSE){

  x.pr = prcomp(t(x),scale.=scale,center=center)
 
  if (screeplot){
    i=5;screeplot(x.pr, type="barplot", 
                  main=paste(context,"methylation PCA Screeplot"), 
                  col = rainbow(i)[i])
  }
  else {
    #loads = loadings(x.pr)
    #loads = x.pr$rotation
    condition = ifelse(treatment == 1, "EPI321", "CONTROL")
    sample.ids = sample.ids

    d <- data.frame(
      PC1=x.pr$x[,1],
      PC2=x.pr$x[,2],
      condition=condition
    )
    p <- ggplot(data=d, aes(x=PC1, y=PC2, color=condition)) +
      geom_point(size=3) + 
      coord_fixed(ratio=1,
                xlim= c(min(d$PC1, d$PC2), max(d$PC1, d$PC2)),
                ylim= c(min(d$PC1, d$PC2), max(d$PC1, d$PC2))
                ) + 
      geom_text(aes(label=rownames(d)), hjust=0, vjust=0, show.legend=FALSE)
    print(p)
  }
  if(obj.return){  return((x.pr))}
}


#' Principal Components Analysis of Methylation data
#' 
#' The function does a PCA analysis using \code{\link[stats]{prcomp}} function 
#' using percent methylation matrix as an input.
#' 
#' @param .Object a \code{methylBase} or \code{methylBaseDB} object
#' @param screeplot a logical value indicating whether to plot the variances 
#'        against the number of the principal component. (default: FALSE)
#' @param adj.lim a vector indicating the propotional adjustment of 
#'        xlim (adj.lim[1]) and 
#'        ylim (adj.lim[2]). This is primarily used for adjusting the visibility
#'        of sample labels on the on the PCA plot. (default: c(0.0004,0.1))
#' @param scale logical indicating if \code{prcomp} should scale the data to 
#'        have unit variance or not (default: TRUE)
#' @param center logical indicating if \code{prcomp} should center the data 
#'        or not (default: TRUE)
#' @param comp vector of integers with 2 elements specifying which components 
#'        to be plotted.
#' @param transpose if TRUE (default) percent methylation matrix will be 
#'        transposed, this is equivalent to doing PCA on variables that are 
#'        regions/bases. The resulting plot will location of samples in the new 
#'        coordinate system if FALSE the variables for the matrix will be samples 
#'        and the resulting plot whill show how each sample (variable) 
#'        contributes to the principle component.the samples that are highly 
#'        correlated should have similar contributions to the principal components.       
#' @param sd.filter  If \code{TRUE}, the bases/regions with low variation will 
#'        be discarded prior to PCA (default:TRUE)
#' @param sd.threshold A numeric value. If \code{filterByQuantile} is \code{TRUE}, 
#'        the value should be between 0 and 1 and the features whose standard 
#'        deviations is less than the quantile denoted by \code{sd.threshold} 
#'        will be removed. If \code{filterByQuantile} is \code{FALSE}, 
#'        then features whose standard deviations is less than the value 
#'        of \code{sd.threshold} will be removed.(default:0.5)
#' @param filterByQuantile A logical determining if \code{sd.threshold} is to be 
#'        interpreted as a quantile of all standard deviation values from 
#'        bases/regions (the default), or as an absolute value
#' @param obj.return if the result of \code{prcomp} function should be returned 
#'        or not. (Default:FALSE)
#' @param chunk.size Number of rows to be taken as a chunk for processing the 
#' \code{methylRawListDB} objects, default: 1e6
#' 
#' @usage PCASamples(.Object, screeplot=FALSE, adj.lim=c(0.0004,0.1), scale=TRUE,
#' center=TRUE,comp=c(1,2),transpose=TRUE,sd.filter=TRUE,
#'            sd.threshold=0.5,filterByQuantile=TRUE,obj.return=FALSE,chunk.size)
#' 
#' @examples
#' data(methylKit) 
#' 
#' # do PCA with filtering rows with low variation, filter rows with standard 
#' # deviation lower than the 50th percentile of Standard deviation distribution
#' PCASamples(methylBase.obj,screeplot=FALSE, adj.lim=c(0.0004,0.1),
#'            scale=TRUE,center=TRUE,comp=c(1,2),transpose=TRUE,sd.filter=TRUE,
#'            sd.threshold=0.5,filterByQuantile=TRUE,obj.return=FALSE)
#' 
#' @section Details:
#' The parameter \code{chunk.size} is only used when working with 
#' \code{methylBaseDB} objects, 
#' as they are read in chunk by chunk to enable processing large-sized 
#' objects which are stored as flat file database.
#' Per default the chunk.size is set to 1M rows, which should work for most 
#' systems. If you encounter memory problems or 
#' have a high amount of memory available feel free to adjust the 
#' \code{chunk.size}.
#' 
#' @return The form of the value returned by \code{PCASamples} is the summary 
#'         of principal component analysis by \code{prcomp}.
#' @note cor option is not in use anymore, since \code{prcomp} is used for PCA 
#'        analysis instead of \code{princomp}
#'  
#'
#' @export
#' @docType methods
#' @rdname PCASamples-methods
setGeneric("myPCASamples", function(.Object, screeplot=FALSE, 
                                  adj.lim=c(0.0004,0.1),
                                  scale=TRUE,center=TRUE,comp=c(1,2),
                                  transpose=TRUE,
                                  sd.filter=TRUE,sd.threshold=0.5,
                                  filterByQuantile=TRUE,obj.return=FALSE,
                                  chunk.size=1e6) 
          standardGeneric("myPCASamples"))

#' @rdname PCASamples-methods
#' @aliases PCASamples,methylBase-method
setMethod("myPCASamples", "methylBase",
  function(.Object, screeplot, adj.lim,scale,center,comp,
                             transpose,sd.filter, sd.threshold, 
                             filterByQuantile,obj.return)
  {
    
    mat      = getData(.Object)
    # remove rows containing NA values, they might be introduced at unite step
    mat      = mat[ rowSums(is.na(mat))==0, ] 
    meth.mat = mat[, .Object@numCs.index]/
      (mat[,.Object@numCs.index] + mat[,.Object@numTs.index] )                                      
    names(meth.mat)=.Object@sample.ids
    
    # if Std. Dev. filter is on remove rows with low variation
    if(sd.filter){
      if(filterByQuantile){
        sds=rowSds(as.matrix(meth.mat))
        cutoff=quantile(sds,sd.threshold)
        meth.mat=meth.mat[sds>cutoff,]
      }else{
        meth.mat=meth.mat[rowSds(as.matrix(meth.mat))>sd.threshold,]
      }
    }
    
    if(transpose){
      .myPcaPlotT(meth.mat,comp1=comp[1],comp2=comp[2],screeplot=screeplot, 
                adj.lim=adj.lim, 
                treatment=.Object@treatment,sample.ids=.Object@sample.ids,
                context=.Object@context
                ,scale=scale,center=center,obj.return=obj.return)
      
    }else{
      .myPcaPlot(meth.mat,comp1=comp[1],comp2=comp[2],screeplot=screeplot, 
               adj.lim=adj.lim, 
               treatment=.Object@treatment,sample.ids=.Object@sample.ids,
               context=.Object@context,
               scale=scale,center=center,  obj.return=obj.return)
    }
    
  }      
)

#' @rdname PCASamples-methods
#' @aliases PCASamples,methylBaseDB-method
setMethod("myPCASamples", "methylBaseDB",
          function(.Object, screeplot, adj.lim,scale,center,comp,
                   transpose,sd.filter, sd.threshold, 
                   filterByQuantile,obj.return,chunk.size)
{
  
  getMethMat <- function(mat,numCs.index,numTs.index,sd.filter, 
                         sd.threshold, filterByQuantile){
    
    # remove rows containing NA values, they might be introduced at unite step
    mat      =mat[ rowSums(is.na(mat))==0, ] 
    
    meth.mat = mat[, numCs.index]/
      (mat[,numCs.index] + mat[,numTs.index] )                                      
    
    
    # if Std. Dev. filter is on remove rows with low variation
    if(sd.filter){
      if(filterByQuantile){
        sds=rowSds(as.matrix(meth.mat))
        cutoff=quantile(sds,sd.threshold)
        meth.mat=meth.mat[sds>cutoff,]
      }else{
        meth.mat=meth.mat[rowSds(as.matrix(meth.mat))>sd.threshold,]
      }
    }
    
  }
  
  meth.mat <- applyTbxByChunk(.Object@dbpath,chunk.size = chunk.size,
                              return.type = "data.frame",FUN=getMethMat,
                              numCs.ind=.Object@numCs.index,
                              numTs.ind=.Object@numTs.index,
                              sd.filter=sd.filter, sd.threshold=sd.threshold, 
                              filterByQuantile=filterByQuantile)
  
  names(meth.mat)=.Object@sample.ids
  
  if(transpose){
    .myPcaPlotT(meth.mat,comp1=comp[1],comp2=comp[2],screeplot=screeplot, 
              adj.lim=adj.lim, 
              treatment=.Object@treatment,sample.ids=.Object@sample.ids,
              context=.Object@context
              ,scale=scale,center=center,obj.return=obj.return)
    
  }else{
    .myPcaPlot(meth.mat,comp1=comp[1],comp2=comp[2],screeplot=screeplot, 
             adj.lim=adj.lim, 
             treatment=.Object@treatment,sample.ids=.Object@sample.ids,
             context=.Object@context,
             scale=scale,center=center,  obj.return=obj.return)
  }
  
}      
)

# Run my version of PCA analysis with prettier plotting
myPCASamples(meth)

```


## Tiling windows analysis
For some situations, it might be desirable to summarize methylation information over tiling windows rather than doing base-pair resolution analysis.
For example, here we tile the genome with windows of 100bp and step-size 100bp and summarize the methylation information on those tiles.
This returns a methylRawList object which can be fed into unite and calculateDiffMeth functions consecutively to get differentially methylated regions.
The tilling function adds up C and T counts from each covered cytosine and returns a total C and T count for each tile.

```{r tiling_window_analysis, echo=FALSE}

# converting my.obj to tile object for sliding 100 bp windows minimum coverage of 5 CpGs 
tile.obj=tileMethylCounts(myobj,win.size=100,step.size=100,cov.bases=5)

# in this version of the code we only required 2 out of the 3 total merged samples (one sample per patient source) to contain a methylation site for it to be included in the comparative analyses if min.per.group is not specified default is all samples must have a specific CpG site or meth tile covered to include it. 
# meth.tile=methylKit::unite(tile.obj, destrand=FALSE, min.per.group = 2L) 

# In this version of the code we are requiring all samples to have a methylation site for it to be included in the comparative analyses.
meth.tile=methylKit::unite(tile.obj, destrand=FALSE)

PCASamples(meth.tile)
# find DMRs 
myDiff.tile=calculateDiffMeth(meth.tile)
```

# Differentially methylated bases or regions
The calculateDiffMeth() function is the main function to calculate differential methylation.
Depending on the sample size per each set it will either use Fisher’s exact or logistic regression to calculate P-values.
P-values will be adjusted to Q-values using SLIM method (Wang, Tuominen, and Tsai 2011).
Note: if we have replicates, the function will automatically use logistic regression.
You can force the calculateDiffMeth() function to use Fisher’s exact test if you pool the replicates when there is only test and control sample groups.

```{r diff_meth_cpg}

## Finding differentially methylated CpGs (differentially methylated regions is in the previous section)
myDiff=calculateDiffMeth(meth)
```


```{r making_bed_files}

# Extracting data from the methylDiff objects and writing to bed files

## for tiling
select.meth <- getData(myDiff.tile) #DMRs

## for CpG sites 
select.meth2 <- getData(myDiff) #DMCs

# write bedfile
meth.bed <- as.data.frame(select.meth) #dmr
meth.bed2 <- as.data.frame(select.meth2)#dmc
write.table(meth.bed, paste0(params$out_path, "/", params$study,".meth.tile.all.bed"), sep="\t", col.names=FALSE, row.names=FALSE, quote=FALSE)
write.table(meth.bed2, paste0(params$out_path, "/", params$study,".meth.cpg.all.bed"), sep="\t", col.names=FALSE, row.names=FALSE, quote=FALSE)
```

## DMR table
```{r percent_methylation_tile}

perc.meth.tile=percMethylation(meth.tile, rowids = TRUE)
perc.meth.tile <- as.data.frame(perc.meth.tile)
perc.meth.tile$avg_treat <- rowMeans(perc.meth.tile[, colnames(perc.meth.tile) %in% treated], na.rm = TRUE)
perc.meth.tile$avg_ctrl <- rowMeans(perc.meth.tile[, colnames(perc.meth.tile) %in% control], na.rm = TRUE)
perc.meth.tile$coord <- rownames(perc.meth.tile)
meth.bed$coord <- paste0(meth.bed$chr,".",meth.bed$start,".",meth.bed$end)
perc.meth.tile <- merge(perc.meth.tile, meth.bed, by="coord")

# This is the final MR file we want!!!! 
write.table(
  perc.meth.tile,
  file = paste0(params$out_path, "/", params$study,".perc.meth.tile.all.tsv"),
  sep="\t",
  col.names=TRUE,
  row.names=FALSE,
  quote=FALSE
)
# This is the final DMR file we want!!!!
perc.meth.tile.sig <- perc.meth.tile[perc.meth.tile$qvalue < 0.01 & abs(perc.meth.tile$meth.diff) > 10,]
total_sig_dmrs <- nrow(perc.meth.tile.sig)

write.table(
  perc.meth.tile.sig,
  file = paste0(params$out_path, "/", params$study,".perc.meth.tile.all.q0.01.methdiff.10.tsv"),
  sep="\t",
  col.names=TRUE,
  row.names=FALSE,
  quote=FALSE
)
```

**`r nrow(perc.meth.tile.sig)`** DMRs were identified with q-value < 0.01 and % methylation difference > 10.

```{r dmr_table}
# Display in table
non_sample_cols <- c("coord", "avg_treat", "avg_ctrl", "chr", "start", "end", "strand", "pvalue", "qvalue", "meth.diff")
sample_cols <- colnames(perc.meth.tile)[!colnames(perc.meth.tile) %in% non_sample_cols]
dmr_table <- perc.meth.tile.sig[ , !colnames(perc.meth.tile.sig) %in% non_sample_cols]
dmr_table <- cbind(
  perc.meth.tile.sig[c("chr", "start", "end")],
  dmr_table,
  perc.meth.tile.sig[c("avg_treat", "avg_ctrl", "pvalue","qvalue", "meth.diff")]
)

round_cols <- c(sample_cols, "avg_treat", "avg_ctrl", "pvalue", "qvalue", "meth.diff")
bp_cols <- c("start", "end")

datatable(
  dmr_table,
  rownames = FALSE,
  extensions = "Buttons",
  options = list(
    dom = "Bfrtip",
    buttons = c("copy", "csv", "excel", "pdf", "print")
  )
) %>%
formatSignif(
  columns = round_cols,
  digits = 4
) %>%
formatRound(
  columns = bp_cols,
  digits = 0,
  interval = NULL
)

```

## Volcano plot

```{r volcano_plot, fig.height=10, fig.width=10}

# Label significance groups
perc.meth.tile$sig.group <- "NS"
perc.meth.tile$sig.group[perc.meth.tile$qvalue < 0.01 & abs(perc.meth.tile$meth.diff) <= 10] <- "qvalue"
perc.meth.tile$sig.group[perc.meth.tile$qvalue >= 0.01 & abs(perc.meth.tile$meth.diff) > 10] <- "meth.diff"
perc.meth.tile$sig.group[perc.meth.tile$qvalue < 0.01 & abs(perc.meth.tile$meth.diff) > 10] <- "qvalue and meth.diff"


# Borrowing EnhancedVolcano theme
th <- theme_bw(base_size = 24) +
  theme(
    legend.background = element_rect(),

    # title, subtitle, and caption
    plot.title = element_text(
      angle = 0,
      size = 18,
      face = 'bold',
      vjust = 1),
    plot.subtitle = element_text(
        angle = 0,
        size = 14,
        face = 'plain',
        vjust = 1),
    plot.caption = element_text(
      angle = 0,
      size = 14,
      face = 'plain',
      vjust = 1),

    # axis text
    axis.text.x = element_text(
      angle = 0,
      size = 18,
      vjust = 1),
    axis.text.y = element_text(
      angle = 0,
      size = 18,
      vjust = 0.5),
    axis.title = element_text(
      size = 18),
    axis.line = element_line(
      size = 0.8,
      colour = 'black'),
    panel.border = element_blank(),
    panel.background = element_blank(),

    # legend
    legend.position = 'top',
    legend.key = element_blank(),
    legend.key.size = unit(0.5, 'cm'),
    legend.text = element_text(
      size = 14),
    title = element_text(
      size = 14),
    legend.title = element_blank()
  )

# Plot Volcano
ggplot(
  data = perc.meth.tile,
  aes(
    x = meth.diff,
    y = -log10(qvalue)
  ) 
  ) +
  geom_point(
    aes(
      color = sig.group,
      alpha = 0.6
    ),
    show.legend = c(
      size = FALSE,
      alpha = FALSE
    ),
    size = 2
  ) +
  geom_vline(
    xintercept = c(-10, 10),
    col = "black",
    linewidth = 0.4,
    linetype = "longdash"
  ) +
  geom_hline(
    yintercept = -log10(0.01),
    col = "black",
    linewidth = 0.4,
    linetype = "longdash"
  ) +
  #ylim(0, 50) + 
  scale_color_manual(
    values=c(
      "NS" = "grey30",
      "qvalue" = "royalblue",
      "meth.diff" = "forestgreen",
      "qvalue and meth.diff" = "red2"
    ),
    breaks=c(
      "NS",
      "qvalue",
      "meth.diff",
      "qvalue and meth.diff"
    )
  ) +
  th +
  labs(
    x = "% methylation change",
    y = "-log10(qvalue)",
    title = "EPI321 vs CONTROL total DMRs",
    subtitle = "Thresholds: qvalue=0.01, meth.diff=10"
  ) +
  guides(
    color = guide_legend(
      override.aes = list(
        size = 5.0
      )
    )
  )
```


```{r percent_methylation_cpg}

perc.meth.cpg=percMethylation(meth, rowids = TRUE)
perc.meth.cpg <- as.data.frame(perc.meth.cpg)
perc.meth.cpg$avg_treat <- rowMeans(perc.meth.cpg[,colnames(perc.meth.cpg) %in% treated], na.rm = TRUE)
perc.meth.cpg$avg_ctrl <- rowMeans(perc.meth.cpg[, colnames(perc.meth.cpg) %in% control], na.rm = TRUE)
perc.meth.cpg$coord <- rownames(perc.meth.cpg)
meth.bed2$coord <- paste0(meth.bed2$chr,".",meth.bed2$start,".",meth.bed2$end)
perc.meth.cpg <- merge(perc.meth.cpg, meth.bed2, by="coord")

# This is the final CpG file we want!!!! 
write.table(
  perc.meth.cpg,
  file = paste0(params$out_path, "/", params$study,".perc.meth.cpg.all.tsv"),
  sep="\t",
  col.names=TRUE,
  row.names=FALSE,
  quote=FALSE
)

# This is the final DMC file we want!!!
perc.meth.cpg.sig <- perc.meth.cpg[perc.meth.cpg$qvalue <=0.01 & abs(perc.meth.cpg$meth.diff) > 10,]
write.table(
  perc.meth.cpg.sig,
  file = paste0(params$out_path, "/", params$study,".perc.meth.cpg.all.q0.01.methdiff.10.tsv"),
  sep="\t",
  col.names=TRUE,
  row.names=FALSE,
  quote=FALSE
)
```


# DMR annotation
```{r dmr_annotation}
# Generate Granges object from DMRs dataframe
dmrs_df <- perc.meth.tile.sig[c("chr", "start", "end", "qvalue", "meth.diff")]
dmrs_gr <- makeGRangesFromDataFrame(
  dmrs_df,
  ignore.strand = TRUE,
  keep.extra.columns = TRUE,
  seqnames.field = "chr",
  start.field = "start",
  end.field = "end"
)
```

## ChromHMM

```{r chromhmm}

# Load ChromHMM annotation
chromhmm_gr <- rtracklayer::import(params$chromhmm_path)
chromhmm_df <- as.data.frame(chromhmm_gr)
chromhmm_df <- chromhmm_df["name"]

# Calculate overlaps between DMRs and ChromHMM annotations
hits_obj <- findOverlaps(dmrs_gr, chromhmm_gr)

dmrs_overlap <- dmrs_df[queryHits(hits_obj),]
chromhmm_overlap <- chromhmm_df[subjectHits(hits_obj),]
ChromHMM.state <- chromhmm_overlap
overlap_df <- cbind(dmrs_overlap, ChromHMM.state)

count_dmr_overlap <- length(unique(queryHits(hits_obj)))
```

```{asis, echo = basename(params$chromhmm_path) == "hg38_genome_100_segments.bed"}
ChromHMM annotations were sourced from https://github.com/ernstlab/full_stack_ChromHMM_annotations
```

```{asis, echo = basename(params$chromhmm_path) == "mm10_100_segments_segments.bed"}
ChromHMM annotations were sourced from https://github.com/ernstlab/mouse_fullStack_annotations
```

**`r count_dmr_overlap` / `r total_sig_dmrs`** 
**(`r round((count_dmr_overlap / total_sig_dmrs) * 100, 2)` %)** of DMRs overlap with ChromHMM annotations.  
Note: a single DMR may have multiple ChromHMM annotations.

```{r chromhmm_table}
# Display in table
round_cols <- c("qvalue", "meth.diff")
bp_cols <- c("start", "end")

datatable(
  overlap_df,
  rownames = FALSE,
  extensions = "Buttons",
  options = list(
    dom = "Bfrtip",
    buttons = c("copy", "csv", "excel", "pdf", "print")
  )
) %>%
formatSignif(
  columns = round_cols,
  digits = 4
) %>%
formatRound(
  columns = bp_cols,
  digits = 0,
  interval = NULL
)
```

## ENCODE cCRE

```{r ccre}

# Load cCRE annotation
ccre_df <- read.table(
  params$ccre_path,
  header = FALSE,
  sep = "\t",
  col.names = c("chr", "start", "end", "accession_old", "accession", "class")
)
# Make starts 1-based
# Not clear in ENCODE documenattion if cCRE starts are 0-based or 1-based
# but since it is a BED file, we will assume it is 0-based
ccre_df$start <- ccre_df$start + 1

ccre_gr <- makeGRangesFromDataFrame(
  ccre_df,
  ignore.strand = TRUE,
  keep.extra.columns = TRUE,
  seqnames.field = "chr",
  start.field = "start",
  end.field = "end",
)

# Calculate overlaps between DMRs and cCRE annotations
hits_obj <- findOverlaps(dmrs_gr, ccre_gr)

dmrs_overlap <- dmrs_df[queryHits(hits_obj),]
ccre_overlap <- ccre_df[subjectHits(hits_obj),]
ccre_overlap <- ccre_overlap[c("accession", "class")]
overlap_df <- cbind(dmrs_overlap, ccre_overlap)

count_dmr_overlap <- length(unique(queryHits(hits_obj)))
```

```{asis, echo = basename(params$ccre_path) == "GRCh38-cCREs.bed"}
cCRE (candidate cis-regulatory element) annotations were sourced from 
https://screen.encodeproject.org/ all human cCREs (hg38) Registry of cCREs V3
```

```{asis, echo = basename(params$ccre_path) == "mm10-cCREs.bed"}
cCRE (candidate cis-regulatory element) annotations were sourced from 
https://screen.encodeproject.org/ all mouse cCREs (mm10) Registry of cCREs V3
```

**`r count_dmr_overlap` / `r total_sig_dmrs`** 
**(`r round((count_dmr_overlap / total_sig_dmrs) * 100, 2)` %)** of DMRs overlap with cCRE annotations.  
Note: a single DMR may have multiple cCRE annotations.

```{r ccre_table}
# Display in table
round_cols <- c("qvalue", "meth.diff")
bp_cols <- c("start", "end")

datatable(
  overlap_df,
  rownames = FALSE,
  extensions = "Buttons",
  options = list(
    dom = "Bfrtip",
    buttons = c("copy", "csv", "excel", "pdf", "print")
  )
) %>%
formatSignif(
  columns = round_cols,
  digits = 4
) %>%
formatRound(
  columns = bp_cols,
  digits = 0,
  interval = NULL
)
```

## ENCODE Blacklist

```{r blacklist}

# Load ChromHMM annotation
blacklist_gr <- rtracklayer::import(params$blacklist_path)
blacklist_df <- as.data.frame(blacklist_gr)
blacklist_df <- blacklist_df["name"]

# Calculate overlaps between DMRs and blacklist annotations
hits_obj <- findOverlaps(dmrs_gr, blacklist_gr)

dmrs_overlap <- dmrs_df[queryHits(hits_obj),]
blacklist_overlap <- blacklist_df[subjectHits(hits_obj),]
blacklist.state <- blacklist_overlap
overlap_df <- cbind(dmrs_overlap, blacklist.state)

count_dmr_overlap <- length(unique(queryHits(hits_obj)))
```

```{asis, echo = basename(params$blacklist_path) == "hg38-blacklist.v2.bed"}
blacklist annotations were sourced from https://github.com/Boyle-Lab/Blacklist/blob/master/lists/hg38-blacklist.v2.bed.gz
```

```{asis, echo = basename(params$blacklist_path) == "mm10-blacklist.v2.bed"}
ChromHMM annotations were sourced from https://github.com/Boyle-Lab/Blacklist/blob/master/lists/mm10-blacklist.v2.bed.gz
```

**`r count_dmr_overlap` / `r total_sig_dmrs`** 
**(`r round((count_dmr_overlap / total_sig_dmrs) * 100, 2)` %)** of DMRs overlap with blacklist annotations.  
Note: a single DMR may have multiple blacklist annotations.

```{r blacklist_table}
# Display in table
round_cols <- c("qvalue", "meth.diff")
bp_cols <- c("start", "end")

datatable(
  overlap_df,
  rownames = FALSE,
  extensions = "Buttons",
  options = list(
    dom = "Bfrtip",
    buttons = c("copy", "csv", "excel", "pdf", "print")
  )
) %>%
formatSignif(
  columns = round_cols,
  digits = 4
) %>%
formatRound(
  columns = bp_cols,
  digits = 0,
  interval = NULL
)
```
